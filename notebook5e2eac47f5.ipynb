{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport xgboost as xg\nfrom xgboost import plot_importance\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV, RepeatedStratifiedKFold\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Lasso\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\nfrom sklearn.utils import shuffle\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom sklearn.utils import shuffle\n\ndf_train = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')\ndf_sub = pd.read_csv('../input/tabular-playground-series-jan-2021/sample_submission.csv')\n\ndf_train.drop('id', inplace=True, axis=1)\n\ny = df_train['target'].values\nX = df_train.drop('target', axis=1)\nprint(y)\nprint(df_sub['id'].values == df_test['id'].values)\ndf_test.drop('id', inplace=True, axis=1)\nprint('Train Data:', df_train.shape)\nprint('Test Data:', df_test.shape)\nX_test = df_test\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":10,"outputs":[{"output_type":"stream","text":"[7.24304259 8.20333114 7.77609076 ... 9.59248653 8.2079506  8.89028481]\n[ True  True  True ...  True  True  True]\nTrain Data: (300000, 15)\nTest Data: (200000, 14)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators = [\n{'name': 'RandomForest',\n'instance': RandomForestRegressor(n_estimators=300, oob_score=True, n_jobs = -1, random_state=42,\ncriterion= 'mse', max_features = 'auto', min_samples_leaf = 1)},\n{'name': 'GBR',\n'instance': GradientBoostingRegressor(loss='ls', alpha=0.95, n_estimators=300)},\n{'name': 'ABR',\n'instance': AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\nn_estimators=300, random_state=np.random.RandomState(1))},\n{'name': 'LSR',\n'instance': Lasso(alpha=1e-8,normalize=True, max_iter=1e5)},\n{'name': 'ETR',\n'instance': ExtraTreesRegressor(n_estimators=300)}\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_best_params(X, y):\n    param_grid = { 'n_estimators' : [200, 300, 500],\n        'max_depth' : [2, 3, 5],\n        'oob_score' : [True, False]\n    }\n    rf = RandomForestRegressor(n_estimators=200, oob_score=True, n_jobs = -1, random_state=42, bootstrap='True',\n    criterion= 'mse', max_features = 'auto', min_samples_leaf = 50)\n    CV_rfc = GridSearchCV(estimator=rf, param_grid=param_grid, cv= 10)\n    CV_rfc.fit(X, y)\n    print (CV_rfc.best_params_)\n    return CV_rfc.best_params_\n\ndef train_dataOld(X_train, y_train, X_val, y_val, estimators):\n    est = {}\n    for estimator in estimators:\n        estimator['instance'].fit(X_train, y_train)\n        cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=10, random_state=42)\n        val_errs = np.sqrt(cross_val_score(estimator=estimator['instance'], X=X_val, y=y_val, cv=cv, scoring='neg_mean_squared_error') * -1)\n        print(f\"validation error: {val_errs.mean()}, std dev: {val_errs.std()}\")\n        est[estimator[‘instance’]] = rmse\n        est[estimator[‘instance’]] = val_errs.mean()\n    model = min(iter(est.keys()), key=lambda k: est[k])\n    print('Lowest rmse:', est[model])\n    print('winner model:', model)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data into train and test sets\nscaler = StandardScaler().fit(X)\nX = scaler.transform(X)\nX_test = scaler.transform(X_test)\nprint(X.shape)\nprint(X_test.shape)\n# Model training process:\nX = xg.DMatrix(X, label=y)\nX_test = xg.DMatrix(X_test)\nxgb_params = {\n'seed': 0,\n'colsample_bytree': 0.8, #changed from 0.8\n'silent': 1,\n'gamma': 0.3, #changed from 0.1\n'reg_alpha': 0.3,\n'subsample': 0.8, #changed from 0.8\n'learning_rate': 0.01, #changed from 0.01\n'objective': 'reg:linear',\n'max_depth': 1,\n'lambda': 0.5,\n'num_parallel_tree': 1,\n'min_child_weight': 10,\n'eval_metric': 'rmse'\n}\nres = xg.cv(xgb_params, X, num_boost_round=1000, nfold=10, seed=0, stratified=False,\nearly_stopping_rounds = 25, verbose_eval=10, show_stdv = True)\nbest_nrounds = res.shape[0]-1\ncv_mean = res.iloc[-1, 0]\ncv_std = res.iloc[-1, 1]\nprint(\"Ensemble CV: {0}+{1}\".format(cv_mean, cv_std))\ngbdt = xg.train(xgb_params, X, best_nrounds)\n# Print the r2 score\nprint(r2_score(y, gbdt.predict(X)))\n# evaluate predictions\nrmse = np.sqrt(mean_squared_error(y, gbdt.predict(X)))\nprint(\"rmse: {}\".format(rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Parameter search using GridSearchCV for XgBoost using scikit learn XGBoostRegreesor API:\n# A parameter grid for XGBoost\nparams = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)], 'subsample':[i/10.0 for i in range(6,11)],\n'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4]}\n# Initialize XGB and GridSearch\nxgb = xg.XGBRegressor(nthread=-1)\ngrid = GridSearchCV(xgb, params, n_jobs = -1)\ngrid.fit(X, y)\n# Print the RMSE score\nprint(grid.best_params_)\nprint(np.sqrt(mean_squared_error(y, grid.best_estimator_.predict(X))))\n# Save the file\ny_test = grid.best_estimator_.predict(X_test)\nframe = pd.DataFrame({'target': y_test}, index=df_sub['id'])\nframe.to_csv('submission.csv')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":14,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}